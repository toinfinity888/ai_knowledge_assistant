import threading
import queue
import sounddevice as sd
import numpy as np
from faster_whisper import WhisperModel
import tempfile
import os
from scipy.io.wavfile import write

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ---
MODEL_NAME = "tiny"       # tiny/base/small/medium
SEGMENT_DURATION = 1      # –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
SAMPLE_RATE = 16000       # —á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
DEVICE = "cpu"            # –º–æ–∂–Ω–æ "auto", "mps" –∏–ª–∏ "cuda" –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ---
model = WhisperModel(MODEL_NAME, device=DEVICE)
audio_queue = queue.Queue()

class ConversationBuffer:
    def __init__(self, max_size=10):
        self.buffer = []
        self.max_size = max_size

    def add(self, text):
        self.buffer.append(text)
        if len(self.buffer) > self.max_size:
            self.buffer.pop(0)

    def get_context(self):
        return " ".join(self.buffer)

buffer = ConversationBuffer()

def audio_callback(indata, frames, time, status):
    """–ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∞—É–¥–∏–æ –≤ –æ—á–µ—Ä–µ–¥—å"""
    if status:
        print(status)
    audio_queue.put(indata.copy())

def save_temp_wav(audio_data):
    """–°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–µ–≥–º–µ–Ω—Ç –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π WAV —Ñ–∞–π–ª"""
    tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
    # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–æ int16
    audio_int16 = np.int16(audio_data / np.max(np.abs(audio_data)) * 32767)
    write(tmp_file.name, SAMPLE_RATE, audio_int16)
    return tmp_file.name

def transcribe_chunk(wav_path):
    """–§–æ–Ω–æ–≤–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è"""
    try:
        segments, info = model.transcribe(wav_path, beam_size=1, vad_filter=True)
        text = " ".join([s.text.strip() for s in segments if s.text.strip()])
        if text:
            buffer.add(text)
            print(f"üìù –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {text}")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {e}")
    finally:
        if os.path.exists(wav_path):
            os.remove(wav_path)

def main():
    print("üé§ –ó–∞–ø–∏—Å—å —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞. –ì–æ–≤–æ—Ä–∏—Ç–µ —á—Ç–æ-–Ω–∏–±—É–¥—å...")
    try:
        with sd.InputStream(channels=1, samplerate=SAMPLE_RATE, callback=audio_callback):
            while True:
                segment = []
                # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ SEGMENT_DURATION —Å–µ–∫—É–Ω–¥
                while len(segment) < SEGMENT_DURATION * SAMPLE_RATE:
                    data = audio_queue.get()
                    segment.append(data)
                segment = np.concatenate(segment, axis=0)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                wav_path = save_temp_wav(segment)
                
                # üî• –ó–∞–ø—É—Å–∫–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –≤ —Ñ–æ–Ω–µ
                threading.Thread(
                    target=transcribe_chunk,
                    args=(wav_path,),
                    daemon=True
                ).start()

    except KeyboardInterrupt:
        print("\nüõë –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.")
        print("üí¨ –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞:")
        print(buffer.get_context())

if __name__ == "__main__":
    main()