# Deepgram Nova-3 Integration - Complete ‚úÖ

## What's New

The system now supports **Deepgram Nova-3** as an alternative transcription backend alongside Whisper and Web Speech API.

### üÜï WebSocket Streaming Now Available!

Deepgram now supports **two modes**:
1. **WebSocket Streaming** (NEW) - True real-time with <1s latency
2. **REST API** - Batch processing with higher latency

See [DEEPGRAM_STREAMING.md](DEEPGRAM_STREAMING.md) for full streaming documentation.

### Key Features:
- **Deepgram Nova-3 Streaming**: WebSocket-based, real-time, <1s latency
- **Deepgram Nova-3 REST**: Cloud-based, batch processing
- **Whisper**: Local, free, good accuracy
- **Web Speech**: Browser-based, instant feedback

### Language Support:
Both Deepgram and Whisper now support multiple languages:
- French (Fran√ßais)
- English
- Spanish (Espa√±ol)
- German (Deutsch)
- Italian (Italiano)
- Portuguese (Portugu√™s)
- Dutch (Nederlands)
- Russian (–†—É—Å—Å–∫–∏–π)
- Chinese (‰∏≠Êñá)
- Japanese (Êó•Êú¨Ë™û)
- Korean (ÌïúÍµ≠Ïñ¥)
- Arabic (ÿßŸÑÿπÿ±ÿ®Ÿäÿ©)

## Setup Instructions

### 1. Get Deepgram API Key

1. Sign up at [https://console.deepgram.com/signup](https://console.deepgram.com/signup)
2. Create a new API key from the dashboard
3. Copy your API key

### 2. Set Environment Variable

**Option A - Terminal (temporary):**
```bash
export DEEPGRAM_API_KEY="your-api-key-here"
```

**Option B - .env file (permanent):**
Create or edit `.env` file in the project root:
```bash
DEEPGRAM_API_KEY=your-api-key-here
```

**Option C - System environment (permanent):**
```bash
# macOS/Linux - Add to ~/.bashrc or ~/.zshrc
echo 'export DEEPGRAM_API_KEY="your-api-key-here"' >> ~/.zshrc
source ~/.zshrc

# Windows - Use System Environment Variables UI
# Or PowerShell:
[System.Environment]::SetEnvironmentVariable('DEEPGRAM_API_KEY', 'your-api-key-here', 'User')
```

### 3. Restart the Server

After setting the environment variable, restart your application:
```bash
python main.py
```

## How to Use

### Configuration Interface

1. Open the configuration interface at: `http://localhost:8000/config` (or your configured PORT env var)

2. In the **"Live Test"** panel header, you'll see two dropdowns:
   - **Transcription Mode**: Choose between:
     - "Backend (Whisper)" - Local processing with Whisper
     - "Backend (Deepgram)" - Cloud API with Deepgram Nova-3
     - "Frontend (Web Speech)" - Browser-based transcription
   - **Language**: Select your language (üá´üá∑ FR, üá¨üáß EN, etc.)

3. **Settings auto-save** when you change the mode or language

4. All settings are automatically persisted to `app/config/transcription_config.json`

### Testing the Transcription

1. In the **"Live Test"** panel:
   - Select your desired mode from the dropdown (Backend Whisper/Deepgram, or Frontend)
   - Select your language
   - Click **"‚óè Record"** to start
   - Speak into your microphone
   - Watch the real-time transcription appear

2. The system will use the selected backend and language automatically

## Configuration Parameters

### New Parameters

| Parameter | Description | Default |
|-----------|-------------|---------|
| `transcription_backend` | Choose 'whisper' or 'deepgram' | whisper |
| `transcription_language` | Language code (fr, en, es, etc.) | fr |

These settings are saved to `app/config/transcription_config.json` and persist across server restarts.

## Implementation Details

### Files Modified/Created:

1. **NEW**: [app/services/deepgram_transcription_service.py](app/services/deepgram_transcription_service.py)
   - Deepgram API integration
   - Nova-3 model configuration
   - Response parsing

2. **MODIFIED**: [app/config/transcription_config.py](app/config/transcription_config.py)
   - Added `transcription_backend` field
   - Added `transcription_language` field

3. **MODIFIED**: [app/services/enhanced_transcription_service.py](app/services/enhanced_transcription_service.py)
   - Integrated Deepgram service
   - Backend selection logic in `_transcribe_buffer()`

4. **MODIFIED**: [app/frontend/templates/config_interface.html](app/frontend/templates/config_interface.html)
   - Added "Transcription Engine" configuration section
   - Backend engine dropdown
   - Language selector dropdown
   - Updated parameter persistence logic

## Troubleshooting

### No API Key Warning
If you see: `"Deepgram API key not configured"` in logs:
- Make sure you set the `DEEPGRAM_API_KEY` environment variable
- Restart the server after setting the variable

### Deepgram Not Working
1. Check your API key is valid
2. Ensure you have internet connectivity
3. Check the logs for specific error messages
4. Try switching back to Whisper to verify the issue is Deepgram-specific

### Configuration Not Saving
- Make sure you click "Apply" after changing settings
- Check file permissions on `app/config/transcription_config.json`
- Look for error messages in the browser console (F12)

## Cost Considerations

- **Whisper**: Free (runs locally, uses CPU/GPU)
- **Web Speech**: Free (uses browser API)
- **Deepgram Nova-3**: Paid API service
  - Pay-as-you-go pricing
  - Check [Deepgram pricing](https://deepgram.com/pricing) for current rates
  - Free tier available for testing

## Next Steps

Consider implementing:
- [ ] Deepgram streaming API for lower latency
- [ ] Batch processing for multiple files
- [ ] Confidence threshold filtering
- [ ] Custom vocabulary support
- [ ] Multi-language auto-detection

---

**Status**: ‚úÖ Fully implemented and ready to use!
**Date**: 2025-12-23
